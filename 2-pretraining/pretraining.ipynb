{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from gptmodel import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 256,\n",
    "    \"emb_dim\": 768,\n",
    "    \"n_heads\": 12,\n",
    "    \"n_layers\": 12,\n",
    "    \"drop_rate\": 0.1,\n",
    "    \"qkv_bias\": False\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval() # turn into eval mode \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "# running untrained model\n",
    "import tiktoken\n",
    "from gptmodel import generate_text_simple\n",
    "\n",
    "# set default device to cuda\n",
    "# torch.set_default_device(\"cuda\")\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0)\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model, \n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "Token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "# the next few cells demonstrate calculating loss --\n",
    "inputs = torch.tensor([[16833, 3626, 6100], # [\"every effort moves\",\n",
    "                        [40, 1107, 588]]) # \"I really like\"]\n",
    "targets = torch.tensor([[3626, 6100, 345 ], # [\" effort moves you\",\n",
    "                        [1107, 588, 11311]]) # \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(probas.shape) # batch size x number of tokens in each row x vocab size\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"Token IDs:\\n\", token_ids)\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1:\" f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0 # [\"every effort moves\",\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]] # get probabiltiies of \"effort moves you\"?\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "text_idx = 1 # \"I really like\"]\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)\n",
    "\n",
    "# the resulting tensors are three indexes representing the probabilities of outputting \"effort moves you\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# calculate the log probabilities of the previous softmax probabiltiies\n",
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "# avg\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)\n",
    "# take negative\n",
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n",
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "# now calculate cross entropy loss between the logits and the targets\n",
    "#  cross entropy loss is the same as what was done in the previous cell, but using pytorch's built in function\n",
    "# measures the difference between the probabilities between the token IDs we want to generate and the \n",
    "# logits which contain all model outputs\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)\n",
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# now start computing the loss on training and validation datasets\n",
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training dataset into 90:10 training to validation\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "# instantiate the dataloader from text-embedding.ipynb\n",
    "from gptmodel import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "# check that the sizes are correct\n",
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate loss of a given batch returned by the data loaders\n",
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(\n",
    "                input_batch, target_batch, model, device\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Training loss: 10.987583266364204\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "# finally, we can calculate the loss of training/validation loaders with the data as input and shifted data as predicted output\n",
    "# (measures how well the training data is predicted by the model)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we've covered calculating loss, start training loop\n",
    "\n",
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode, disables dropout?\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to keep track of loss progress and generate samples\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.819, Val loss 9.926\n",
      "Ep 1 (Step 000005): Train loss 8.068, Val loss 8.340\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.622, Val loss 7.054\n",
      "Ep 2 (Step 000015): Train loss 6.043, Val loss 6.601\n",
      "Every effort moves you, and,, and,, the,,,, and,.                                   \n",
      "Ep 3 (Step 000020): Train loss 5.509, Val loss 6.564\n",
      "Ep 3 (Step 000025): Train loss 5.346, Val loss 6.392\n",
      "Every effort moves you, and to the to the of the picture to the picture.                                     \n",
      "Ep 4 (Step 000030): Train loss 4.719, Val loss 6.248\n",
      "Ep 4 (Step 000035): Train loss 4.727, Val loss 6.359\n",
      "Every effort moves you of the \"I the picture.  \"I had the of the          \"I had the picture and I had been the donkey of the \"I\"I had been the picture\"I\n",
      "Ep 5 (Step 000040): Train loss 3.869, Val loss 6.129\n",
      "Every effort moves you know the \"Oh, and he had to the fact of the last word.     \"Oh, and to see. \"Oh, and he had been. \"Oh, and in the fact--I had been\n",
      "Ep 6 (Step 000045): Train loss 3.554, Val loss 6.198\n",
      "Ep 6 (Step 000050): Train loss 3.037, Val loss 6.135\n",
      "Every effort moves you know the fact, and pushed one of the--I-chairs.                                    \n",
      "Ep 7 (Step 000055): Train loss 2.901, Val loss 6.116\n",
      "Ep 7 (Step 000060): Train loss 2.157, Val loss 6.124\n",
      "Every effort moves you know,\" was one of the picture--I felt it--as of Jack's not till, I was, the fact, the fact that, I was his pictures.                \n",
      "Ep 8 (Step 000065): Train loss 1.739, Val loss 6.181\n",
      "Ep 8 (Step 000070): Train loss 1.442, Val loss 6.199\n",
      "Every effort moves you?\"  \"Yes--I glanced after him, and uncertain. \"Oh, and--I looked up, I had been through my work of his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.102, Val loss 6.248\n",
      "Ep 9 (Step 000080): Train loss 0.832, Val loss 6.285\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with the last word.        He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
      "Ep 10 (Step 000085): Train loss 0.593, Val loss 6.374\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with equanimity. Gisburn's an awful simpleton, and muddling; then I looked at the donkey again. I saw that, the man of the hour. The\n",
      "Training completed in 0.43 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "# uncomment for new model\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "\n",
    "# adamw optimizer - minimalizes model complexity and prevents overfitting\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1) # model.parameters returns all trainable parameters\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# note: generated text in the samples match the training text verbatim because of the small dataset \n",
    "# we've used and multiple epochs\n",
    "# plot loss vs epochs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you?\"\n",
      "\n",
      "\"Yes--quite insensible to the fact with equanimity. Gisburn's an awful simpleton\n"
     ]
    }
   ],
   "source": [
    "# now try to introduce more randomness in training process to generate more original text\n",
    "# recall the generate_text_simple functoin\n",
    "\n",
    "model.to(\"cpu\")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=25,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n",
      "toward\n",
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "# section to demonstrate two methods: top-k sampling and temperature scaling \n",
    "# using simple example\n",
    "\n",
    "# top-k sampling: randomly taking the top k most probable next tokens\n",
    "# this exmaple is k = size(vocab)?\n",
    "# instead of only taking the most probable token every time\n",
    "vocab = {\n",
    "    \"closer\": 0,\n",
    "    \"every\": 1,\n",
    "    \"effort\": 2,\n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5,\n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "}\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "print(inverse_vocab[next_token_id])\n",
    "\n",
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])\n",
    "\n",
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123)\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item()\n",
    "    for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# temperature scaling - scales logits to either flatten or sharpen the probability distribution\n",
    "# (this occurs before softmax, so scaling it is dividing the negative log values)\n",
    "# higher temperature, more flat distribution\n",
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "temperatures = [1, 0.1, 5]\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T)\n",
    "    for T in temperatures]\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i],\n",
    "    bar_width, label=f'Temperature = {T}')\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "# how to implement top k sampling\n",
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float('-inf')),\n",
    "    other=next_token_logits\n",
    ")\n",
    "print(new_logits)\n",
    "\n",
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now implement in ou]r original model, in a new generate text function\n",
    "def generate(model, idx, max_new_tokens, context_size,\n",
    "    temperature=0.0, top_k=None, eos_id=None):\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        if top_k is not None:\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(\n",
    "                logits < min_val,\n",
    "                torch.tensor(float('-inf')).to(logits.device),\n",
    "                logits\n",
    "            )\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)\n",
    "        if idx_next == eos_id:\n",
    "            break\n",
    "        idx = torch.cat((idx, idx_next), dim=1)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you know began to happen. It was not it was such a good; and\n"
     ]
    }
   ],
   "source": [
    "# generate text using new function\n",
    "torch.manual_seed(123)\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### PRE-TRAINING DONE ########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202626/1625268370.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to load the weights saved\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this saves the weights and the optimizer\n",
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_202626/1272228378.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# how to load both weights and optimizer\n",
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('gpt_download.py', <http.client.HTTPMessage at 0x7fb96e528e50>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now load weights from gpt-2\n",
    "\n",
    "# download code to retrieve weights\n",
    "import urllib.request\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/\"\n",
    "    \"LLMs-from-scratch/main/ch05/\"\n",
    "    \"01_main-chapter-code/gpt_download.py\"\n",
    ")\n",
    "filename = url.split('/')[-1]\n",
    "urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 00:01:50.637266: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 154389504 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "# retrieve weights\n",
    "from gpt_download import download_and_load_gpt2\n",
    "settings, params = download_and_load_gpt2(\n",
    "    model_size=\"124M\", models_dir=\"gpt2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n",
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n",
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)\n",
    "print(\"Parameter dictionary keys:\", params.keys())\n",
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new model following gpt2 config\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "model_name = \"gpt2-small (124M)\"\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "\n",
    "NEW_CONFIG.update({\"context_length\": 1024})\n",
    "\n",
    "NEW_CONFIG.update({\"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
